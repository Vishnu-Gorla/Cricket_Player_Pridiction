# -*- coding: utf-8 -*-
"""Copy of ODI_Analysis.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UAZv9ij9I7Io0fMi1R_xEmG4Xqy_v9on

<center>
<b><i><font color="Sky Blue" size="8">Odi Cricket Analysis</font></i></b>
</center>

<h2><b><font color="gold">Introduction</font></b></h2>
"""

# Mounting Google Drive

from google.colab import drive
drive.mount('/content/drive')

# Importing Requires Libraries

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import os

# Importing warnings to ignore warnings

import warnings
warnings.filterwarnings("ignore", category=DeprecationWarning)

# Path for files from drive
odi_ball_file = '/content/drive/MyDrive/Cricket_Project/data/model_ready/Ball By Ball/odi_ball_by_ball.csv'
odi_info_file = '/content/drive/MyDrive/Cricket_Project/data/model_ready/Info/odi_info.csv'
odi_summary_file = '/content/drive/MyDrive/Cricket_Project/data/model_ready/Summary/odi_summary.csv'
odi_venue_file = '/content/drive/MyDrive/Cricket_Project/data/model_ready/odi_match_id_final_venue.csv'
players_file = '/content/drive/MyDrive/Cricket_Project/data/player_lookup_all_formats.csv'

# Loading the CSV's into a DataFrame
df_odi_ball = pd.read_csv(odi_ball_file, low_memory=False)
df_odi_info = pd.read_csv(odi_info_file, low_memory=False)
df_odi_summary = pd.read_csv(odi_summary_file, low_memory=False)
df_odi_venue = pd.read_csv(odi_venue_file, low_memory=False)
df_players_lookup = pd.read_csv(players_file, low_memory=False)

# Verifying the shape of Dataframes

print(f"Ball By Ball shape: {df_odi_ball.shape}")
print(f"Info shape: {df_odi_info.shape}")
print(f"Summary shape: {df_odi_summary.shape}")
print(f"Venue shape: {df_odi_venue.shape}")
print(f"Players shape: {df_players_lookup.shape}")

"""<h2><b><font color="gold">Data Cleaning</font></b></h2>"""

# Checking for missing values in each column
missing_counts = df_odi_ball.isnull().sum()
print(missing_counts)

# Renaming columns for better readability

df_odi_ball = df_odi_ball.rename(columns={
    'runs.batter': 'batsman_runs',
    'runs.extras': 'extras',
    'runs.total': 'total_runs'
})

# Remove completely empty columns
df_odi_ball.dropna(axis=1, how='all', inplace=True)

# Fill numeric columns
if 'batsman_runs' in df_odi_ball.columns:
    df_odi_ball['batsman_runs'] = df_odi_ball['batsman_runs'].fillna(0).astype(int)
if 'extras' in df_odi_ball.columns:
    df_odi_ball['extras'] = df_odi_ball['extras'].fillna(0).astype(int)

# Fill string columns
if 'bowler' in df_odi_ball.columns:
    df_odi_ball['bowler'] = df_odi_ball['bowler'].fillna("Unknown")

# Create wicket flag
if 'wicket.kind' in df_odi_ball.columns:
    df_odi_ball['is_wicket'] = df_odi_ball['wicket.kind'].notnull().astype(int)
else:
    df_odi_ball['is_wicket'] = 0

"""<h2><b><font color="gold">Data Pre-Processing</font></b></h2>"""

# Standardizing the Match ID Column Name across all ODI dataframes
for df in [df_odi_ball, df_odi_info, df_odi_summary, df_odi_venue]:
    if 'Match Id' in df.columns:
        df.rename(columns={'Match Id': 'Match_ID'}, inplace=True)

# Removing unnesasary columns before merging

required_info_cols = [
    'Match_ID', 'balls_per_over', 'city', 'dates', 'event.name',
    'event.match_number', 'gender', 'match_type', 'match_type_number',
    'season', 'teams', 'player_of_match', 'outcome.winner', 'outcome.by.runs',
    'outcome.by.wickets', 'outcome.result', 'outcome.summary'
]

# Use only columns present in your file

df_odi_info = df_odi_info[[col for col in required_info_cols if col in df_odi_info.columns]].copy()

# Merging Ball data and Info data

df_odi_ball = df_odi_ball.merge(df_odi_info, on='Match_ID', how='left')

# merging Ball data and venue data
df_odi_ball = df_odi_ball.merge(df_odi_venue, on='Match_ID', how='left')

# Keeping only odi players from the player lookup table and remove any duplicate player names.
odi_players_lookup = df_players_lookup[df_players_lookup['format'] == 'ODI'].drop_duplicates(subset=['name'])

# Merge player_id into the main ball-by-ball DataFrame.
# For each ball, finding the player's ID by matching the batter's name with the odi player names.
df_odi_ball = df_odi_ball.merge(
    odi_players_lookup[['player_id', 'name']],
    left_on='batter',
    right_on='name',
    how='left'
)

# Remove the extra 'name' column from the DataFrame after merging, since we only need the 'player_id', not the name itself.
df_odi_ball = df_odi_ball.drop(columns=['name'])

"""<h2><b><font color="gold">Finding batting team and opponent team for better analysis</font></b></h2>"""

# Finding opponent team
''' This code defines a function to identify the opposing team for each ball,
handling cases where the team names may be stored as a list, a comma-separated string,
or a stringified list like "['India', 'Pakistan']". It then applies this function to the data,
creating a new column with the opponent team’s name.'''

def get_opposition(row):
    teams = row['teams']
    if isinstance(teams, list):
        pass
    elif isinstance(teams, str):
        s = teams.strip()
        # Handle stringified lists by removing surrounding [ ]
        if s.startswith('[') and s.endswith(']'):
            s = s[1:-1]
        # Split and strip quotes/spaces
        teams = [t.strip().strip("'").strip('"') for t in s.split(',')]

    else:
        return None

    # Safety: require exactly two teams after parsing
    if not isinstance(teams, list) or len(teams) != 2:
        return None

    bt = row['batting_team']
    if bt == teams[0]:
        return teams[1]
    elif bt == teams[1]:
        return teams[0]
    else:
        return None

# Apply to ODI
df_odi_ball['opposition'] = df_odi_ball.apply(get_opposition, axis=1)
print("ODI missing opposition count:", df_odi_ball['opposition'].isna().sum())

# Finding Batting Team
if 'team' in df_odi_ball.columns:
    df_odi_ball['batting_team'] = df_odi_ball['team']
print("Missing batting_team count:", df_odi_ball['batting_team'].isna().sum())

"""<h2><b><font color="gold">Finding ball number of that over</font></b></h2>"""

# Finding ball number of that over
''' This function assigns ball numbers in the format 'over.ball' for each delivery,
 ensuring only legal balls (not wides or no-balls) increment the count within each over.
 It then adds these ball numbers as a new column in the DataFrame.'''


def assign_ball_numbers_exact(df):
    ball_numbers = []
    prev_over = None
    ball_count = 1

    for idx, row in df.iterrows():
        current_over = row['over']
        wide = row['extras.wides']
        noball = row['extras.noballs']

        # New over: reset ball count to 1
        if idx == 0 or current_over != prev_over:
            ball_count = 1

        ball_numbers.append(f"{current_over}.{ball_count}")

        # Only increment ball count if this ball is LEGAL
        if (wide == 0) and (noball == 0):
            if ball_count < 6:
                ball_count += 1
        # If not legal, ball_count does NOT increment

        prev_over = current_over

    df['ball_number'] = ball_numbers
    return df


df_odi_ball = assign_ball_numbers_exact(df_odi_ball)

"""<h2><b><font color="gold">Sorting Data Column</font></b></h2>"""

import pandas as pd

# 1) Convert 'dates' from list-like string to datetime
df_odi_ball['dates'] = (
    df_odi_ball['dates'].astype(str).str.extract(r'(\d{4}-\d{2}-\d{2})')[0]
)
df_odi_ball['dates'] = pd.to_datetime(df_odi_ball['dates'], errors='coerce')

# 2) Convert 'ball_number' to float
df_odi_ball['ball_number'] = pd.to_numeric(df_odi_ball['ball_number'], errors='coerce')

# Quick check
print(df_odi_ball[['dates', 'ball_number']].dtypes)
print(df_odi_ball[['dates', 'ball_number']].head())

"""<h2><b><font color="gold">Overall analysis visualizations</font></b></h2>

"""

# Most Runs scored Battters in odi

plt.figure(figsize=(12,5))
top_batsmen = df_odi_ball.groupby('batter')['batsman_runs'].sum().sort_values(ascending=False).head(10)
sns.barplot(
    x=top_batsmen.values,
    y=top_batsmen.index,
    hue=top_batsmen.index,
    palette="viridis",
    legend=False
)

plt.title("Top 10 Most Odi Run Scorers ", color = 'red')
plt.xlabel("Total Runs",  color='blue', fontsize=12)
plt.ylabel("Batter", color='green', fontsize=12)
plt.savefig("/content/drive/MyDrive/Cricket_Project/Visualizations/Odi_Top_10_Run_Scoreres.png")
plt.show()

# Most wicket taking bowlers in odi

plt.figure(figsize=(12,5))
top_bowlers = df_odi_ball[df_odi_ball['is_wicket']==1].groupby('bowler').size().sort_values(ascending=False).head(10)
sns.barplot(
    x=top_bowlers.values,
    y=top_bowlers.index,
    hue=top_bowlers.index,
    palette="viridis",
    legend=False
)
plt.xlabel('Wickets', color='blue', fontsize=12)
plt.ylabel('Bowler', color='green', fontsize=12)
plt.title('Top 10 Odi Bowlers by Wickets', color = 'red')
plt.savefig("/content/drive/MyDrive/Cricket_Project/Visualizations/Odi_Top_10_Wicket_Takers.png")
plt.show()

# Total runs scored team for match in odi's

runs_per_innings = df_odi_ball.groupby(['Match_ID', 'batting_team'])['total_runs'].sum().reset_index()

plt.figure(figsize=(14,6))
sns.boxplot(x='batting_team', y='total_runs', data=runs_per_innings)
plt.title("Distribution of Total Runs per Match by Batting Team in Odi's", color = 'red')
plt.xlabel("Batting Team",  color='blue', fontsize=12)
plt.ylabel("Runs", color='green', fontsize=12)
plt.xticks(rotation=90)
plt.savefig("/content/drive/MyDrive/Cricket_Project/Visualizations/Odi_Overall_Runs_ByTeam.png")
plt.show()

# Total Wickets taken by Bowling team per match

wickets_per_innings = df_odi_ball.groupby(['Match_ID', 'team'])['is_wicket'].sum().reset_index()

plt.figure(figsize=(14,6))
sns.boxplot(x='team', y='is_wicket', data=wickets_per_innings)
plt.title("Distribution of Total Wickets Taken By Bowling Team Per Match in Odi's", color = 'red')
plt.xlabel("Bowling Team", color='blue', fontsize=12)
plt.ylabel("Wickets", color='green', fontsize=12)
plt.xticks(rotation=90)
plt.savefig("/content/drive/MyDrive/Cricket_Project/Visualizations/Odi_Overall_Wickets_ByTeam.png")
plt.show()

# Number of matches won by each team

df_odi_info['outcome.winner'] = df_odi_info['outcome.winner'].fillna('No Result')
plt.figure(figsize=(12,6))
winner_counts = df_odi_info['outcome.winner'].value_counts().reset_index()
winner_counts.columns = ['Winner', 'Count']
ax = sns.barplot(data=winner_counts, x='Winner', y='Count')
plt.title("Number of Matches Won by Each Team", color = 'red')
plt.xlabel("Winning Team", color='blue', fontsize=12)
plt.ylabel("Number of Matches", color='green', fontsize=12)
plt.xticks(rotation=75)
plt.tight_layout()
plt.savefig("/content/drive/MyDrive/Cricket_Project/Visualizations/Odi_Most_Wins_ByTeam.png")
plt.show()

"""<h2><b><font color="gold">Batting Metrics of a Batter</font></b></h2>"""

# Basic batting metrics by batter

odi_batting_stats = (
    df_odi_ball.groupby('batter').agg(
        runs_scored = ('batsman_runs', 'sum'),
        balls_faced = ('batsman_runs', 'count'),
        fours = ('batsman_runs', lambda x: (x == 4).sum()),
        sixes = ('batsman_runs', lambda x: (x == 6).sum()),
        dismissals = ('is_wicket', 'sum')
    ).reset_index()
)

odi_innings_scores = df_odi_ball.groupby(['batter', 'Match_ID'])['batsman_runs'].sum().reset_index()
advanced = (
    odi_innings_scores.groupby('batter').agg(
        high_score = ('batsman_runs', 'max'),
        fifties = ('batsman_runs', lambda x: ((x >= 50) & (x < 100)).sum()),
        hundreds = ('batsman_runs', lambda x: ((x >= 100) & (x < 200)).sum()),
        double_hundreds = ('batsman_runs', lambda x: (x >= 200).sum()),
        score_std = ('batsman_runs', 'std')
    ).reset_index()
)

# Round off score_std with 2 decimal values
advanced['score_std'] = advanced['score_std'].round(2)

# Merging Basic Metrics and Adavance Metrics

odi_batting_stats = odi_batting_stats.merge(advanced, on='batter', how='left')

# Post-processing adding strike rate, batting average to the dataframe

odi_batting_stats['strike_rate'] = (odi_batting_stats['runs_scored'] / odi_batting_stats['balls_faced'] * 100).replace([np.inf, np.nan], 0).round(2)
odi_batting_stats['batting_average'] = (odi_batting_stats['runs_scored'] / odi_batting_stats['dismissals']).replace([np.inf, np.nan], 0).round(2)

# Finding Recent Form from last 5 matches
N = 5
odi_innings_scores['recent_form_runs'] = (
    odi_innings_scores.groupby('batter')['batsman_runs']
    .transform(lambda x: x.shift(1).rolling(window=N, min_periods=1).mean())
)
odi_innings_scores['career_avg_runs'] = (
    odi_innings_scores.groupby('batter')['batsman_runs'].transform(lambda x: x.expanding().mean())
)

"""<h2><b><font color="gold">Metrics of Batter Vs Opponent</font></b></h2>"""

# Metrics of Batter vs Opponent

odi_batter_vs_opp = (
    df_odi_ball.groupby(['batter', 'opposition']).agg(
        innings_played=('Match_ID', pd.Series.nunique),
        runs_scored=('batsman_runs', 'sum'),
        balls_faced=('batsman_runs', 'count'),
        dismissals=('is_wicket', 'sum')
    ).reset_index()
)
odi_batter_vs_opp['batting_average'] = (odi_batter_vs_opp['runs_scored'] /odi_batter_vs_opp['dismissals']).replace([np.inf, np.nan], 0).round(2)
odi_batter_vs_opp['strike_rate'] = (odi_batter_vs_opp['runs_scored'] / odi_batter_vs_opp['balls_faced'] * 100).replace([np.inf, np.nan], 0).round(2)

# Adding Boundary Percentage & Balls per Boundary to the dataframe

odi_batting_stats['boundary_pct'] = (
    (odi_batting_stats['fours'] + odi_batting_stats['sixes']) / odi_batting_stats['balls_faced'] * 100
).replace([np.inf, np.nan], 0).round(2)

odi_batting_stats['balls_per_boundary'] = (
    odi_batting_stats['balls_faced'] / (odi_batting_stats['fours'] + odi_batting_stats['sixes'])
).replace([np.inf, np.nan], 0).round(2)

# Wide Format Batter Overall Average Metrics and Average Vs Opponent

odi_batter_vs_opp_pivot = (
    odi_batter_vs_opp.pivot(index='batter', columns='opposition', values='batting_average')
    .add_prefix('avg_vs_')
    .reset_index()
)
odi_batting_summary = odi_batting_stats.merge(odi_batter_vs_opp_pivot, on='batter', how='left')

"""<h2><b><font color="gold">Metrics of Batter Vs venue</font></b></h2>"""

# Runs for each batter at each venue

odi_innings_scores = (
    df_odi_ball.groupby(['batter', 'venue', 'Match_ID'])['batsman_runs']
    .sum()
    .reset_index()
)

# Counting 50s and 100s at each venue for each batter

odi_fifty_hundred_stats = (
    odi_innings_scores.groupby(['batter', 'venue'])
    .agg(
        fifties=('batsman_runs', lambda x: ((x >= 50) & (x < 100)).sum()),
        hundreds=('batsman_runs', lambda x: ((x >= 100) & (x < 200)).sum()),
        double_hundreds=('batsman_runs', lambda x: (x >= 200).sum())
    )
    .reset_index()
)

# Core Batting Stats by batter and venue

odi_batter_vs_venue = (
    df_odi_ball.groupby(['batter', 'venue']).agg(
        innings_played=('Match_ID', pd.Series.nunique),
        runs_scored=('batsman_runs', 'sum'),
        balls_faced=('batsman_runs', 'count'),
        dismissals=('is_wicket', 'sum'),
        fours=('batsman_runs', lambda x: (x == 4).sum()),
        sixes=('batsman_runs', lambda x: (x == 6).sum())
    ).reset_index()
)

# Adding 50s/100s/200s to the venue stats df

odi_batter_vs_venue = odi_batter_vs_venue.merge(
    odi_fifty_hundred_stats, on=['batter', 'venue'], how='left'
)

# Advanced Batting Metrics

# Finding Batting Average for each venue

odi_batter_vs_venue['batting_average'] = (
    odi_batter_vs_venue['runs_scored'] / odi_batter_vs_venue['dismissals']
).replace([np.inf, np.nan], 0).round(2)

# Finding Strike Rate for each venue

odi_batter_vs_venue['strike_rate'] = (
    odi_batter_vs_venue['runs_scored'] / odi_batter_vs_venue['balls_faced'] * 100
).replace([np.inf, np.nan], 0).round(2)

# Filling NaN for fifties/hundreds/double_hundreds ----
odi_batter_vs_venue[['fifties', 'hundreds', 'double_hundreds']] = odi_batter_vs_venue[[
    'fifties', 'hundreds', 'double_hundreds'
]].fillna(0).astype(int)

"""<h2><b><font color="gold">Bowling Metrics for Bowler</font></b></h2>"""

# A maiden = an over with total_runs == 0 for a bowler in a match

odi_overs_summary = (
    df_odi_ball.groupby(['bowler', 'Match_ID', 'batting_team', 'over'])
    .agg(total_runs_in_over=('total_runs', 'sum'))
    .reset_index()
)
odi_overs_summary['is_maiden'] = (odi_overs_summary['total_runs_in_over'] == 0).astype(int)

odi_maidens_by_bowler = (
    odi_overs_summary.groupby('bowler')['is_maiden']
    .sum()
    .reset_index()
    .rename(columns={'is_maiden': 'maidens'})
)

# Bowling Metrics for bowler

odi_agg_dict = {
    'balls_bowled': ('bowler', 'count'),
    'runs_conceded': ('total_runs', 'sum'),
    'wickets': ('is_wicket', 'sum'),
    'fours_conceded': ('batsman_runs', lambda x: (x == 4).sum()),
    'sixes_conceded': ('batsman_runs', lambda x: (x == 6).sum()),
}

odi_bowling_stats = df_odi_ball.groupby('bowler').agg(**odi_agg_dict).reset_index()
odi_bowling_stats = odi_bowling_stats.merge(odi_maidens_by_bowler, on='bowler', how='left')
odi_bowling_stats['maidens'] = odi_bowling_stats['maidens'].fillna(0).astype(int)

# Per-Innings Bowling Summary

odi_innings_bowling = (
    df_odi_ball.groupby(['bowler', 'Match_ID', 'batting_team'])
    .agg(
        runs_conceded=('total_runs', 'sum'),
        wickets=('is_wicket', 'sum'),
        balls_bowled=('bowler', 'count')
    ).reset_index()
)

# Best innings figures (most wickets and then fewest runs)

odi_best_innings = (
    odi_innings_bowling.loc[
        odi_innings_bowling.groupby('bowler')['wickets'].idxmax()
    ][['bowler', 'wickets', 'runs_conceded']]
    .rename(columns={'wickets': 'best_innings_wickets', 'runs_conceded': 'best_innings_runs_conceded'})
)

# 5WI, std dev
advanced_bowl = (
    odi_innings_bowling.groupby('bowler').agg(
        five_wicket_hauls=('wickets', lambda x: (x >= 5).sum()),
        wickets_std=('wickets', 'std')
    ).reset_index()
)
advanced_bowl['wickets_std'] = advanced_bowl['wickets_std'].replace([np.inf, np.nan], 0).round(2)

# Merging advanced metrics

advanced_bowl = advanced_bowl.merge(odi_best_innings, on='bowler', how='left')

# Merging Basic and Advanced metrics

odi_bowling_stats = odi_bowling_stats.merge(advanced_bowl, on='bowler', how='left')
odi_bowling_stats['best_innings_wickets'] = odi_bowling_stats['best_innings_wickets'].fillna(0).astype(int)

# Post-Processing Metrics: Bowling Average, Strike Rate, Economy

# Finding Bowling Average

odi_bowling_stats['bowling_average'] = (
    odi_bowling_stats['runs_conceded'] / odi_bowling_stats['wickets']
).replace([np.inf, np.nan], 0).round(2)


# Finding Bowler Strike rate

odi_bowling_stats['strike_rate'] = (
    odi_bowling_stats['balls_bowled'] / odi_bowling_stats['wickets']
).replace([np.inf, np.nan], 0).round(2)


# Finding Bowler Economy

odi_bowling_stats['economy'] = (
    odi_bowling_stats['runs_conceded'] / odi_bowling_stats['balls_bowled'] * 6
).replace([np.inf, np.nan], 0).round(2)


# Finding Wicket per balls

odi_bowling_stats['balls_per_wicket'] = (
    odi_bowling_stats['balls_bowled'] / odi_bowling_stats['wickets']
).replace([np.inf, np.nan], 0).round(2)


#Finding Boundaary Percentage

odi_bowling_stats['boundary_pct'] = (
    (odi_bowling_stats['fours_conceded'] + odi_bowling_stats['sixes_conceded']) /
    odi_bowling_stats['balls_bowled'] * 100
).replace([np.inf, np.nan], 0).round(2)

"""<h2><b><font color="gold">Bowler Vs Opponent Analysis</font></b></h2>"""

# Bowler vs Opposition Analysis

odi_bowler_vs_opp = (
    df_odi_ball.groupby(['bowler', 'opposition']).agg(
        matches=('Match_ID', pd.Series.nunique),
        balls_bowled=('bowler', 'count'),
        runs_conceded=('total_runs', 'sum'),
        wickets=('is_wicket', 'sum'),
    ).reset_index()
)

# Adding Bowling_Avg, Balls_Bowled, Economy fields to the dataframe

odi_bowler_vs_opp['bowling_average'] = (
    odi_bowler_vs_opp['runs_conceded'] / odi_bowler_vs_opp['wickets']
).replace([np.inf, np.nan], 0).round(2)
odi_bowler_vs_opp['strike_rate'] = (
    odi_bowler_vs_opp['balls_bowled'] / odi_bowler_vs_opp['wickets']
).replace([np.inf, np.nan], 0).round(2)
odi_bowler_vs_opp['economy'] = (
    odi_bowler_vs_opp['runs_conceded'] / odi_bowler_vs_opp['balls_bowled'] * 6
).replace([np.inf, np.nan], 0).round(2)

# Wide Format (Pivot for Averages by Opposition)
odi_bowler_vs_opp_pivot = (
    odi_bowler_vs_opp.pivot(index='bowler', columns='opposition', values='bowling_average')
    .add_prefix('avg_vs_')
    .reset_index()
)
odi_bowling_summary = odi_bowling_stats.merge(odi_bowler_vs_opp_pivot, on='bowler', how='left')

"""<h2><b><font color="gold"> Bowler Vs venue Analysis</font></b></h2>"""

# Bowler Vs venue

odi_bowler_vs_venue = (
    df_odi_ball.groupby(['bowler', 'venue']).agg(
        matches=('Match_ID', pd.Series.nunique),
        balls_bowled=('bowler', 'count'),
        runs_conceded=('total_runs', 'sum'),
        wickets=('is_wicket', 'sum'),
        fours_conceded=('batsman_runs', lambda x: (x == 4).sum()),
        sixes_conceded=('batsman_runs', lambda x: (x == 6).sum())
    ).reset_index()
)

# Adding Bowling_Avg, Strike rate, Economy fields to the dataframe

odi_bowler_vs_venue['bowling_average'] = (
    odi_bowler_vs_venue['runs_conceded'] / odi_bowler_vs_venue['wickets']
).replace([np.inf, np.nan], 0).round(2)
odi_bowler_vs_venue['strike_rate'] = (
    odi_bowler_vs_venue['balls_bowled'] / odi_bowler_vs_venue['wickets']
).replace([np.inf, np.nan], 0).round(2)
odi_bowler_vs_venue['economy'] = (
    odi_bowler_vs_venue['runs_conceded'] / odi_bowler_vs_venue['balls_bowled'] * 6
).replace([np.inf, np.nan], 0).round(2)

# Finding Recent Form from last 5 matches

N = 5
odi_innings_bowling['recent_form_wickets'] = (
    odi_innings_bowling.groupby('bowler')['wickets']
    .transform(lambda x: x.shift(1).rolling(window=N, min_periods=1).mean())
)

odi_innings_bowling['career_avg_wickets'] = (
    odi_innings_bowling.groupby('bowler')['wickets'].transform(lambda x: x.expanding().mean())
)

"""***Importing All The Required Libraries***

"""

# Importing all the required Libraries
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
from xgboost import XGBRegressor
from lightgbm import LGBMRegressor
from sklearn.model_selection import RandomizedSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.preprocessing import MinMaxScaler
from sklearn.metrics import mean_absolute_error, r2_score
import joblib

"""<h2><b><font color="gold"> Preparing Batting Data for Modeling</font></b></h2>

***Base rows (one per batter–match)***
"""

# Select match-level columns per batter
base_cols = [
    'Match_ID','batter','venue','opposition','season','city',
    'match_type','event.match_number','outcome.winner',
    'outcome.by.runs','outcome.by.wickets','outcome.result','player_id'
]
odi_bat_model_df = df_odi_ball[base_cols].drop_duplicates()

"""***Merge career stats***"""

# Add overall career batting stats per batter (suffix _career)
career = odi_batting_stats.copy()
career = career.rename(columns={c: f"{c}_career" for c in career.columns if c != 'batter'})
odi_bat_model_df = odi_bat_model_df.merge(career, on='batter', how='left')

"""***Merge innings scores***"""

# Add per-match runs (target) and simple form features
inn_cols = ['batter','Match_ID','batsman_runs','recent_form_runs','career_avg_runs']
inn_cols = [c for c in inn_cols if c in odi_innings_scores.columns]  # safe selection
inn = odi_innings_scores[inn_cols].copy()

odi_bat_model_df = odi_bat_model_df.merge(inn, on=['batter','Match_ID'], how='left')
print("After innings:", odi_bat_model_df.shape)

"""***Merge batter vs opponent stats***"""

# Add each batter's record versus each opposition (suffix _vs_opp)
vs_opp = odi_batter_vs_opp.copy()
vs_opp = vs_opp.rename(columns={c: f"{c}_vs_opp" for c in vs_opp.columns if c not in ['batter','opposition']})
odi_bat_model_df = odi_bat_model_df.merge(vs_opp, on=['batter','opposition'], how='left')

"""***Merge batter vs venue stats***"""

# Add each batter's record at each venue (suffix _vs_venue)
vs_venue = odi_batter_vs_venue.copy()
vs_venue = vs_venue.rename(columns={c: f"{c}_vs_venue" for c in vs_venue.columns if c not in ['batter','venue']})
odi_bat_model_df = odi_bat_model_df.merge(vs_venue, on=['batter','venue'], how='left')

"""***Merge batting summary***"""

# Add overall summary metrics per batter (suffix _summary)
summary = odi_batting_summary.copy()
summary = summary.rename(columns={c: f"{c}_summary" for c in summary.columns if c != 'batter'})
odi_bat_model_df = odi_bat_model_df.merge(summary, on='batter', how='left')

"""***Venue–opposition aggregates***"""

# Compute extra stats per (batter, venue, opposition) from ball-by-ball and merge
tmp = df_odi_ball[['batter','venue','opposition','Match_ID','batsman_runs','ball_number','wicket.player_out']].copy()
tmp['is_batter_out'] = (tmp['wicket.player_out'] == tmp['batter']).astype(int)

venue_opp = tmp.groupby(['batter','venue','opposition']).agg(
    innings_played_venue_opp=('Match_ID','nunique'),
    runs_scored_venue_opp=('batsman_runs','sum'),
    balls_faced_venue_opp=('ball_number','count'),
    dismissals_venue_opp=('is_batter_out','sum')
).reset_index()

match_runs = tmp.groupby(['batter','venue','opposition','Match_ID'])['batsman_runs'].sum().reset_index()
f50  = match_runs.assign(is50 =(match_runs['batsman_runs']>=50 ).astype(int)) \
                 .groupby(['batter','venue','opposition'])['is50'].sum().reset_index(name='fifties_venue_opp')
f100 = match_runs.assign(is100=(match_runs['batsman_runs']>=100).astype(int)) \
                 .groupby(['batter','venue','opposition'])['is100'].sum().reset_index(name='hundreds_venue_opp')

venue_opp = venue_opp.merge(f50,  on=['batter','venue','opposition'], how='left')
venue_opp = venue_opp.merge(f100, on=['batter','venue','opposition'], how='left')

venue_opp['batting_average_venue_opp'] = np.where(
    venue_opp['dismissals_venue_opp'] > 0,
    venue_opp['runs_scored_venue_opp'] / venue_opp['dismissals_venue_opp'],
    venue_opp['runs_scored_venue_opp']
)

odi_bat_model_df = odi_bat_model_df.merge(venue_opp, on=['batter','venue','opposition'], how='left')

"""***Match order + recent runs form***"""

# Create per-batter match order and rolling recent form (runs) with windows 3, 5, 10
ord_df = df_odi_ball[['batter','Match_ID','dates','season','event.match_number']].drop_duplicates().copy()
ord_df['dates'] = pd.to_datetime(ord_df['dates'], errors='coerce')
ord_df = ord_df.sort_values(['batter','dates','season','event.match_number','Match_ID'])
ord_df['Match_ID_order'] = ord_df.groupby('batter').cumcount() + 1

odi_bat_model_df = odi_bat_model_df.merge(ord_df[['batter','Match_ID','Match_ID_order']], on=['batter','Match_ID'], how='left')
print("After match order:", odi_bat_model_df.shape)

odi_bat_model_df = odi_bat_model_df.sort_values(['batter','Match_ID_order']).copy()
for w in [3, 5, 10]:
    odi_bat_model_df[f'recent_runs_mean_{w}'] = (
        odi_bat_model_df.groupby('batter')['batsman_runs'].shift(1).rolling(w, min_periods=1).mean()
    )

"""***Clean missing values and encode categoricals***"""

# Fill NAs, define X/y, and label-encode object features for modeling
from sklearn.preprocessing import LabelEncoder

odi_bat_model_df = odi_bat_model_df.loc[:, ~odi_bat_model_df.columns.duplicated()].copy()

for c in odi_bat_model_df.select_dtypes(include='object').columns:
    odi_bat_model_df[c] = odi_bat_model_df[c].fillna('Unknown')
for c in odi_bat_model_df.select_dtypes(include=[np.number]).columns:
    odi_bat_model_df[c] = odi_bat_model_df[c].fillna(odi_bat_model_df[c].median())

y = odi_bat_model_df['batsman_runs']
drop_cols = ['batsman_runs','Match_ID','batter','player_id']
drop_cols = [c for c in drop_cols if c in odi_bat_model_df.columns]
X = odi_bat_model_df.drop(columns=drop_cols)

encoders = {}
# Encode categorical columns directly into X
for c in X.select_dtypes(include='object').columns:
    le = LabelEncoder()
    X[c] = le.fit_transform(X[c].astype(str))
    encoders[c] = le

print("After clean + encode:", X.shape)

joblib.dump(encoders, "label_encoders_odi_batters.joblib")

maps = {c: {cls: int(i) for i, cls in enumerate(le.classes_)} for c, le in encoders.items()}
joblib.dump(maps, "label_maps_odi_batters.joblib")

odi_bat_model_df.to_csv("odi_bat_model_df.csv", index=False)

# Cross checking any object columns before model training
object_cols = list(X.select_dtypes(include=['object']).columns)
print("Columns to be label encoded:", object_cols)

"""***Splitting Data for Model Training***"""

# Spliting data with all the columns
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""<h2><b><font color="gold">Random Forest</font></b></h2>"""

# Training Random Forest Model
# This code trains a Random Forest model to predict runs, and prints out how well the model performed using MAE and R2 metrics

rf_odi_bat = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42, n_jobs=-1)
rf_odi_bat.fit(X_train, y_train)

# Predicting
y_pred = rf_odi_bat.predict(X_test)

# Round predicted values
y_pred_rounded = np.round(y_pred).astype(int)

# Evaluate on rounded predictions
mae = mean_absolute_error(y_test, y_pred_rounded)
r2 = r2_score(y_test, y_pred_rounded)

# Print results
print(f"Random Forest MAE (Rounded): {mae:.2f}")
print(f"Random Forest R2 (Rounded): {r2:.3f}")

# Comparing Actual Runs and Predicted Runs

comparison_df = pd.DataFrame({
    'Actual Runs': y_test.values,
    'Predicted Runs': np.round(y_pred).astype(int)
})

# Show the first 20 rows for a quick check
print(comparison_df.head(20))

# Plotting the top 20 feature importances as a bar chart from Random Forest Regressor

importances = rf_odi_bat.feature_importances_
indices = np.argsort(importances)[::-1]
plt.figure(figsize=(12,5))
plt.title("Feature Importance (Random Forest)")
plt.bar(range(20), importances[indices][:20])
plt.xticks(range(20), [X.columns[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold"> Linear Regression</font></b></h2>"""

# Training Linear Regression Model
#This code trains Linear Regression model to predict runs, and prints out how well the model performed using MAE and R2 metrics


lr_odi_bat = LinearRegression()
lr_odi_bat.fit(X_train, y_train)

# Predicting
y_pred = lr_odi_bat.predict(X_test)

# Round predicted values
y_pred_rounded = np.round(y_pred).astype(int)

# Evaluate on rounded predictions
mae = mean_absolute_error(y_test, y_pred_rounded)
r2 = r2_score(y_test, y_pred_rounded)

# Print results
print(f"Linear Regression MAE (Rounded): {mae:.2f}")
print(f"Linear Regression R2 (Rounded): {r2:.3f}")

# Comparing Actual Runs and Predicted Runs

comparison_df = pd.DataFrame({
    'Actual Runs': y_test.values,
    'Predicted Runs': np.round(y_pred).astype(int)
})

# Show the first 20 rows for a quick check
print(comparison_df.head(20))

# Get absolute coefficients as feature importance
coefs = np.abs(lr_odi_bat.coef_)
indices = np.argsort(coefs)[::-1]

# Plot the top 20 features
plt.figure(figsize=(12, 5))
plt.title("Feature Importance (Linear Regression)")
plt.bar(range(20), coefs[indices][:20])
plt.xticks(range(20), [X.columns[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">XGBoost</font></b></h2>"""

# Training XGBoost Model
#This code trains a XGBoost model to predict runs, and prints out how well the model performed using MAE and R2 metrics


import xgboost as xgb

xgb_reg_odi_bat = xgb.XGBRegressor(
    n_estimators=100,       # Number of trees
    learning_rate=0.1,      # Step size shrinkage
    max_depth=6,            # Depth of trees
    subsample=0.8,          # Row sampling
    colsample_bytree=0.8,   # Feature sampling
    random_state=42,
    n_jobs=-1               # Use all CPU cores
)

xgb_reg_odi_bat.fit(X_train, y_train)

# Predict using XGBoost
y_pred = xgb_reg_odi_bat.predict(X_test)

# Round predicted values
y_pred_rounded = np.round(y_pred).astype(int)

# Evaluate with rounded predictions
mae = mean_absolute_error(y_test, y_pred_rounded)
r2 = r2_score(y_test, y_pred_rounded)

# Print results
print(f"XGBoost MAE (Rounded): {mae:.2f}")
print(f"XGBoost R2 (Rounded): {r2:.3f}")

# Comparing Actual Runs and Predicted Runs

comparison_df = pd.DataFrame({
    'Actual Runs': y_test.values,
    'Predicted Runs': np.round(y_pred).astype(int)
})

# Show the first 20 rows for a quick check
print(comparison_df.head(20))

# Get feature importances from the XGBoost model
importances = xgb_reg_odi_bat.feature_importances_
indices = np.argsort(importances)[::-1]

# Plot the top 20 features
plt.figure(figsize=(12, 5))
plt.title("Feature Importance (XGBoost)")
plt.bar(range(20), importances[indices][:20])
plt.xticks(range(20), [X.columns[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">LightGBM</font></b></h2>"""

# Training LightGBM Model
#This code trains a LightGBM model to predict runs, and prints out how well the model performed using MAE and R2 metrics

import lightgbm as lgb

X.columns = X.columns.str.replace(' ', '_')

lgb_reg_odi_bat = lgb.LGBMRegressor(
    n_estimators=100,
    learning_rate=0.1,
    max_depth=7,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42,
    verbose=-1,
    n_jobs=-1
)

lgb_reg_odi_bat.fit(X_train, y_train)

# Predict using LightGBM
y_pred = lgb_reg_odi_bat.predict(X_test)

# Round predicted values
y_pred_rounded = np.round(y_pred).astype(int)

# Evaluate with rounded predictions
mae = mean_absolute_error(y_test, y_pred_rounded)
r2 = r2_score(y_test, y_pred_rounded)

# Print results
print(f"LightGBM MAE (Rounded): {mae:.2f}")
print(f"LightGBM R2 (Rounded): {r2:.3f}")

# Comparing Actual Runs and Predicted Runs

comparison_df = pd.DataFrame({
    'Actual Runs': y_test.values,
    'Predicted Runs': np.round(y_pred).astype(int)
})

# Show the first 20 rows for a quick check
print(comparison_df.head(20))

# Get feature importances
importances = lgb_reg_odi_bat.feature_importances_
indices = np.argsort(importances)[::-1]

# Plot the top 20 important features
plt.figure(figsize=(12, 5))
plt.title("Feature Importance (LightGBM)")
plt.bar(range(20), importances[indices][:20])
plt.xticks(range(20), [X.columns[i] for i in indices[:20]], rotation=90)
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">Standardization</font></b></h2>"""

# Fix column names before scaling
X.columns = X.columns.str.replace(' ', '_')

# Standardizing features and preserving column names
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Train-test split
X_train_std, X_test_std, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Training and evaluating models

# Random Forest
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train_std, y_train)
y_pred_rf = np.round(rf.predict(X_test_std)).astype(int)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)
print(f"Random Forest (Rounded): MAE: {mae_rf:.3f} R2: {r2_rf:.3f}")

# Linear Regression
lr = LinearRegression()
lr.fit(X_train_std, y_train)
y_pred_lr = np.round(lr.predict(X_test_std)).astype(int)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)
print(f"Linear Regression (Rounded): MAE: {mae_lr:.3f} R2: {r2_lr:.3f}")

# XGBoost
xgb_reg = XGBRegressor(random_state=42, verbosity=0)
xgb_reg.fit(X_train_std, y_train)
y_pred_xgb = np.round(xgb_reg.predict(X_test_std)).astype(int)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
print(f"XGBoost (Rounded): MAE: {mae_xgb:.3f} R2: {r2_xgb:.3f}")

# LightGBM
lgb_reg = LGBMRegressor(random_state=42)
lgb_reg.fit(X_train_std, y_train)
y_pred_lgb = np.round(lgb_reg.predict(X_test_std)).astype(int)
mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
r2_lgb = r2_score(y_test, y_pred_lgb)
print(f"LightGBM (Rounded): MAE: {mae_lgb:.3f} R2: {r2_lgb:.3f}")

"""<h2><b><font color="gold">Normalization</font></b></h2>"""

# Normalizing and preserving feature names
scaler_norm = MinMaxScaler()
X_norm = pd.DataFrame(scaler_norm.fit_transform(X), columns=X.columns)

# Train-test split
X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=0.2, random_state=42)

# Training and evaluating models

#  Random Forest
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train_norm, y_train_norm)
y_pred_rf = np.round(rf.predict(X_test_norm)).astype(int)
mae_rf = mean_absolute_error(y_test_norm, y_pred_rf)
r2_rf = r2_score(y_test_norm, y_pred_rf)
print(f"Random Forest (Rounded): MAE: {mae_rf:.3f} R2: {r2_rf:.3f}")

#  Linear Regression
lr = LinearRegression()
lr.fit(X_train_norm, y_train_norm)
y_pred_lr = np.round(lr.predict(X_test_norm)).astype(int)
mae_lr = mean_absolute_error(y_test_norm, y_pred_lr)
r2_lr = r2_score(y_test_norm, y_pred_lr)
print(f"Linear Regression (Rounded): MAE: {mae_lr:.3f} R2: {r2_lr:.3f}")

#  XGBoost
xgb_reg = XGBRegressor(random_state=42, verbosity=0)
xgb_reg.fit(X_train_norm, y_train_norm)
y_pred_xgb = np.round(xgb_reg.predict(X_test_norm)).astype(int)
mae_xgb = mean_absolute_error(y_test_norm, y_pred_xgb)
r2_xgb = r2_score(y_test_norm, y_pred_xgb)
print(f"XGBoost (Rounded): MAE: {mae_xgb:.3f} R2: {r2_xgb:.3f}")

#  LightGBM
lgb_reg = LGBMRegressor(random_state=42)
lgb_reg.fit(X_train_norm, y_train_norm)
y_pred_lgb = np.round(lgb_reg.predict(X_test_norm)).astype(int)
mae_lgb = mean_absolute_error(y_test_norm, y_pred_lgb)
r2_lgb = r2_score(y_test_norm, y_pred_lgb)
print(f"LightGBM (Rounded): MAE: {mae_lgb:.3f} R2: {r2_lgb:.3f}")

"""<h2><b><font color="gold">LightGBM Hyperparameter Tuning</font></b></h2>


"""

# Defining the parameter grid
param_dist = {
    'num_leaves': [15, 31, 63, 127],
    'max_depth': [-1, 5, 10, 15],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300, 500],
    'min_child_samples': [5, 10, 20, 30],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

X.columns = X.columns.str.replace(' ', '_')

# Initialize model
lgbm = LGBMRegressor(random_state=42, verbose=-1)

# RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=lgbm,
    param_distributions=param_dist,
    n_iter=30,  # reduce if very slow
    scoring='neg_mean_absolute_error',
    cv=3,
    random_state=42,
    n_jobs=-1
)

# Fit the random search
random_search.fit(X_train, y_train)

# Predicting and evaluating
best_lgbm = random_search.best_estimator_
y_pred = np.round(best_lgbm.predict(X_test)).astype(int)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Best Parameters:", random_search.best_params_)
print(f"Tuned LightGBM (Rounded): MAE: {mae:.3f}, R2: {r2:.3f}")

results = pd.DataFrame({
    'Actual': y_test.values.astype(int),
    'Predicted (rounded)': y_pred.astype(int)
})
results['Error'] = results['Predicted (rounded)'] - results['Actual']

print("Actual vs Predicted (first 20 rows):")
print(results.head(20))

# Use your tuned model from RandomizedSearchCV
importances_lgb = pd.Series(best_lgbm.feature_importances_, index=X.columns)
importances_lgb_sorted = importances_lgb.sort_values(ascending=False).head(20)

plt.figure(figsize=(10, 6))
importances_lgb_sorted.plot(kind='barh')
plt.title("Top 20 Feature Importances (Tuned LightGBM)")
plt.gca().invert_yaxis()
plt.xlabel("Importance")
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">SHAP explanations for tuned LightGBM </font></b></h2>"""

import shap

# Use a small sample of X_test for speed (uses all if smaller than 1000)
X_explain = X_test.sample(n=min(1000, len(X_test)), random_state=42)

# Build explainer and compute SHAP values
explainer = shap.TreeExplainer(best_lgbm)
shap_values = explainer.shap_values(X_explain)

"""***SHAP Beeswarm Plot***"""

# SHAP beeswarm showing impact of each feature on individual predictions
plt.figure(figsize=(12, 8))
shap.summary_plot(
    shap_values,
    X_explain,
    max_display=10,
    show=False
)
plt.title("SHAP value (impact on model output)")
plt.tight_layout()
plt.show()

"""***SHAP Bar Plot***

"""

# SHAP bar chart showing average absolute impact of each feature
plt.figure(figsize=(12, 8))
shap.summary_plot(
    shap_values,
    X_explain,
    plot_type="bar",
    max_display=10,
    show=False
)
plt.title("mean(|SHAP value|) – average impact on model output")
plt.xlabel("mean(|SHAP value|) (average impact on model output)")
plt.tight_layout()
plt.show()

"""***SHAP Single-Feature Dependence Plot***"""

# SHAP dependence plot showing how one feature’s values affect predictions

# Pick the top feature by mean absolute SHAP value
mean_abs = np.abs(shap_values).mean(axis=0)
top_idx = np.argsort(mean_abs)[-1]
top_feat = X_explain.columns[top_idx]   # e.g., "vs_venue_wickets"

plt.figure(figsize=(10, 6))
shap.dependence_plot(
    top_feat,          # feature to visualize
    shap_values,       # SHAP values from explainer
    X_explain,         # data sample used for explanations
    show=False
)
plt.title(f"SHAP Dependence Plot – {top_feat}")
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold"> Preparing Bowling Data for Modeling</font></b></h2>

***Copy base dataframe & fill extras***
"""

# Make a working copy
odi_df = df_odi_ball.copy()

# Fill missing extras with 0
odi_df['extras.wides']   = odi_df['extras.wides'].fillna(0)
odi_df['extras.noballs'] = odi_df['extras.noballs'].fillna(0)
odi_df['extras.byes']    = odi_df['extras.byes'].fillna(0)
odi_df['extras.legbyes'] = odi_df['extras.legbyes'].fillna(0)

"""***Per‑ball helper columns***"""

# Legal delivery: not a wide and not a no-ball
odi_df['is_legal_ball'] = ((odi_df['extras.wides'] == 0) &
                           (odi_df['extras.noballs'] == 0)).astype(int)

# Runs conceded per ball = batsman runs + wides + no-balls
odi_df['runs_conceded_ball'] = (
    odi_df['batsman_runs'].fillna(0) +
    odi_df['extras.wides'] +
    odi_df['extras.noballs']
)

# Bowler extras (only wides + no-balls)
odi_df['bowler_extras_ball'] = odi_df['extras.wides'] + odi_df['extras.noballs']

"""***Calculate runs conceded per over***"""

# Total runs conceded in each over for each bowler in each match
odi_over_runs = (
    odi_df.groupby(['Match_ID', 'bowler', 'over'])['runs_conceded_ball']
          .sum()
          .reset_index(name='runs_in_over')
)

"""***Identify maiden overs per bowler per match***"""

# Mark maiden overs (0 runs conceded in an over)
odi_over_runs['is_maiden_over'] = (odi_over_runs['runs_in_over'] == 0).astype(int)

# Count maiden overs for each bowler in each match
odi_maidens = (
    odi_over_runs.groupby(['Match_ID', 'bowler'])['is_maiden_over']
                 .sum()
                 .reset_index(name='maidens_in_match')
)

"""***Match‑level aggregates + opposition + metadata***"""

# Totals per (Match_ID, bowler)
odi_agg = (
    odi_df.groupby(['Match_ID', 'bowler'])
          .agg({
              'is_legal_ball': 'sum',
              'runs_conceded_ball': 'sum',
              'is_wicket': 'sum',
              'bowler_extras_ball': 'sum'
          })
          .reset_index()
          .rename(columns={
              'is_legal_ball': 'balls_bowled_in_match',
              'runs_conceded_ball': 'runs_conceded_in_match',
              'is_wicket': 'wickets_in_match',
              'bowler_extras_ball': 'extras_in_match'
          })
)

# Economy (runs per over) and Strike Rate (balls per wicket)
odi_agg['econ_rate_in_match']   = odi_agg['runs_conceded_in_match'] / (odi_agg['balls_bowled_in_match'] / 6)
odi_agg['strike_rate_in_match'] = odi_agg['balls_bowled_in_match'] / odi_agg['wickets_in_match'].replace(0, np.nan)

# Opposition = batting_team faced most balls in that match
odi_opp = (
    odi_df.groupby(['Match_ID', 'bowler', 'batting_team'])
          .size()
          .reset_index(name='balls_against_team')
    .sort_values(['Match_ID','bowler','balls_against_team'], ascending=[True, True, False])
    .drop_duplicates(['Match_ID','bowler'])
    .rename(columns={'batting_team': 'opposition'})[['Match_ID','bowler','opposition']]
)

# Match metadata (first row per match)
odi_meta = (
    odi_df.groupby('Match_ID')[[
        'venue','season','match_type','outcome.winner','outcome.by.runs',
        'outcome.by.wickets','outcome.result','dates'
    ]].first().reset_index()
    .rename(columns={'dates': 'match_date'})
)

# Combine all parts
odi_bowl_model_df = (
    odi_agg.merge(odi_maidens, on=['Match_ID','bowler'], how='left')
           .merge(odi_opp,     on=['Match_ID','bowler'], how='left')
           .merge(odi_meta,    on='Match_ID',            how='left')
)

# Clean wickets to int
odi_bowl_model_df['wickets_in_match'] = odi_bowl_model_df['wickets_in_match'].fillna(0).astype(int)

"""***Merge career bowling stats***"""

# Keep relevant columns and prefix with career_
odi_career_cols = ['bowler','balls_bowled','runs_conceded','wickets','fours_conceded',
                   'sixes_conceded','maidens','five_wicket_hauls','wickets_std',
                   'best_innings_wickets','best_innings_runs_conceded',
                   'bowling_average','strike_rate','economy','balls_per_wicket','boundary_pct']

odi_career_df = odi_bowling_stats[odi_career_cols].rename(
    columns={c: f'career_{c}' for c in odi_career_cols if c != 'bowler'}
)

odi_bowl_model_df = odi_bowl_model_df.merge(odi_career_df, on='bowler', how='left')

"""***Merge opposition‑level stats***"""

odi_opp_df = odi_bowler_vs_opp[[
    'bowler','opposition','matches','balls_bowled','runs_conceded','wickets',
    'bowling_average','strike_rate','economy'
]].rename(columns={
    'matches':'vs_opp_matches',
    'balls_bowled':'vs_opp_balls_bowled',
    'runs_conceded':'vs_opp_runs_conceded',
    'wickets':'vs_opp_wickets',
    'bowling_average':'vs_opp_bowling_average',
    'strike_rate':'vs_opp_strike_rate',
    'economy':'vs_opp_economy'
})

odi_bowl_model_df = odi_bowl_model_df.merge(odi_opp_df, on=['bowler','opposition'], how='left')

"""***Merge venue‑level stats***"""

odi_venue_df = odi_bowler_vs_venue[[
    'bowler','venue','matches','balls_bowled','runs_conceded','wickets',
    'fours_conceded','sixes_conceded','bowling_average','strike_rate','economy'
]].rename(columns={
    'matches':'vs_venue_matches',
    'balls_bowled':'vs_venue_balls_bowled',
    'runs_conceded':'vs_venue_runs_conceded',
    'wickets':'vs_venue_wickets',
    'fours_conceded':'vs_venue_fours_conceded',
    'sixes_conceded':'vs_venue_sixes_conceded',
    'bowling_average':'vs_venue_bowling_average',
    'strike_rate':'vs_venue_strike_rate',
    'economy':'vs_venue_economy'
})

odi_bowl_model_df = odi_bowl_model_df.merge(odi_venue_df, on=['bowler','venue'], how='left')

"""***Merge innings‑level stats***"""

odi_ib_match = (
    odi_innings_bowling
    .groupby(['Match_ID','bowler'], as_index=False)
    .agg({
        'runs_conceded':'sum',
        'wickets':'sum',
        'balls_bowled':'sum',
        'recent_form_wickets':'first',
        'career_avg_wickets':'first',
        'batting_team':'first'
    })
    .rename(columns={
        'runs_conceded':'innings_runs_conceded',
        'wickets':'innings_wickets',
        'balls_bowled':'innings_balls_bowled',
        'batting_team':'innings_batting_team'
    })
)

odi_bowl_model_df = odi_bowl_model_df.merge(odi_ib_match, on=['Match_ID','bowler'], how='left')

"""***Merge opponent averages***"""

odi_opp_avg_cols = [c for c in odi_bowling_summary.columns if c.startswith('avg_vs_')]
odi_bowler_opp_avg = odi_bowling_summary[['bowler'] + odi_opp_avg_cols].copy()

odi_bowl_model_df = odi_bowl_model_df.merge(odi_bowler_opp_avg, on='bowler', how='left')

"""***Create recent‑form rolling averages***"""

windows = [3, 5, 10, 15, 20]

# Ensure base columns exist (simple fills)
odi_bowl_model_df['innings_wickets'] = odi_bowl_model_df['innings_wickets'].fillna(0)
odi_bowl_model_df['innings_runs_conceded'] = odi_bowl_model_df['innings_runs_conceded'].fillna(0)

# Rolling means for wickets
for w in windows:
    col = f'recent_wickets_mean_{w}'
    odi_bowl_model_df[col] = (
        odi_bowl_model_df.groupby('bowler')['innings_wickets']
                         .transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())
    )

# Rolling means for runs conceded
for w in windows:
    col = f'recent_runs_conceded_mean_{w}'
    odi_bowl_model_df[col] = (
        odi_bowl_model_df.groupby('bowler')['innings_runs_conceded']
                         .transform(lambda s: s.shift(1).rolling(w, min_periods=1).mean())
    )

"""***Create ratio features***"""

# Venue vs Career
odi_bowl_model_df['venue_wickets_ratio'] = (
    odi_bowl_model_df['vs_venue_wickets'] / odi_bowl_model_df['career_avg_wickets'].replace(0, np.nan)
)
odi_bowl_model_df['venue_sr_ratio'] = (
    odi_bowl_model_df['vs_venue_strike_rate'] / odi_bowl_model_df['career_strike_rate'].replace(0, np.nan)
)

# Opposition vs Career
odi_bowl_model_df['opp_wickets_ratio'] = (
    odi_bowl_model_df['vs_opp_wickets'] / odi_bowl_model_df['career_avg_wickets'].replace(0, np.nan)
)
odi_bowl_model_df['opp_sr_ratio'] = (
    odi_bowl_model_df['vs_opp_strike_rate'] / odi_bowl_model_df['career_strike_rate'].replace(0, np.nan)
)

# Clean infinities
for c in ['venue_wickets_ratio','venue_sr_ratio','opp_wickets_ratio','opp_sr_ratio']:
    odi_bowl_model_df[c] = odi_bowl_model_df[c].replace([np.inf, -np.inf], np.nan)

"""***Rolling wickets vs opposition & venue***"""

# Sort by bowler/opposition/date for opposition-based rolling
odi_bowl_model_df = odi_bowl_model_df.sort_values(['bowler','opposition','match_date'])

# Rolling wickets vs opposition
for w in [3, 5, 10]:
    col = f'recent_wickets_vs_opp_mean_{w}'
    odi_bowl_model_df[col] = (
        odi_bowl_model_df
        .groupby(['bowler','opposition'])['innings_wickets']
        .transform(lambda s: s.shift(1).rolling(window=w, min_periods=1).mean())
    )

# Sort by bowler/venue/date for venue-based rolling
odi_bowl_model_df = odi_bowl_model_df.sort_values(['bowler','venue','match_date'])

# Rolling wickets vs venue
for w in [3, 5, 10]:
    col = f'recent_wickets_vs_venue_mean_{w}'
    odi_bowl_model_df[col] = (
        odi_bowl_model_df
        .groupby(['bowler','venue'])['innings_wickets']
        .transform(lambda s: s.shift(1).rolling(window=w, min_periods=1).mean())
    )

"""***Experience counter + check***"""

# Sort by bowler/date for experience counter
odi_bowl_model_df = odi_bowl_model_df.sort_values(['bowler','match_date'])

# Count prior matches for each bowler
odi_bowl_model_df['appearance_num'] = odi_bowl_model_df.groupby('bowler').cumcount()

# Target
odi_target_col = 'wickets_in_match'

# Leakage columns (IDs, target, direct-per-match stats)
odi_leak_cols = [
    'Match_ID','match_date','wickets_in_match','player_id','bowler',
    'balls_bowled_in_match','runs_conceded_in_match','extras_in_match',
    'maidens_in_match','econ_rate_in_match','strike_rate_in_match',
    'innings_runs_conceded','innings_wickets','innings_balls_bowled','innings_batting_team'
]

# Build X, y
odi_drop_cols = [c for c in odi_leak_cols if c in odi_bowl_model_df.columns]
X = odi_bowl_model_df.drop(columns=odi_drop_cols, errors='ignore')
y = odi_bowl_model_df[odi_target_col].astype(int)

from sklearn.preprocessing import LabelEncoder

# Fill numeric NaNs with median
for c in X.select_dtypes(include=[np.number]).columns:
    X[c] = X[c].fillna(X[c].median())

encoders = {}
# Encode categorical columns directly into X
for c in X.select_dtypes(include='object').columns:
    le = LabelEncoder()
    X[c] = le.fit_transform(X[c].astype(str))
    encoders[c] = le

joblib.dump(encoders, "label_encoders_odi_bowl.joblib")

odi_bowl_model_df.to_csv("odi_bowl_model_df.csv", index=False)

maps = {c: {cls: int(i) for i, cls in enumerate(le.classes_)} for c, le in encoders.items()}
joblib.dump(maps, "label_maps_odi_bowl.joblib")

# Cross checking any object columns before model training
object_cols = list(X.select_dtypes(include=['object']).columns)
print("Columns to be label encoded:", object_cols)

"""***Splitting Data for Model Training***"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

"""<h2><b><font color="gold">Random Forest</font></b></h2>"""

# Training Random Forest Model
# This code trains a Random Forest model to predict runs, and prints out how well the model performed using MAE and R2 metrics
rf_odi_bowl = RandomForestRegressor(n_estimators=100, random_state=42)
rf_odi_bowl.fit(X_train, y_train)

# Predict on test data
y_pred = rf_odi_bowl.predict(X_test)
y_pred_rounded = np.round(y_pred).astype(int)

# Evaluation
mae = mean_absolute_error(y_test, y_pred_rounded)
r2 = r2_score(y_test, y_pred_rounded)

print(f"🎯 Random Forest (Wickets Prediction)")
print(f"MAE: {mae:.3f}")
print(f"R²: {r2:.3f}")

# Create a DataFrame to compare actual and predicted values
results_df = pd.DataFrame({
    'Actual Wickets': y_test.values,
    'Predicted Wickets': y_pred_rounded
})

# Show top 20 rows
print(results_df.head(20))

# Feature importances
importances = pd.Series(rf_odi_bowl.feature_importances_, index=X.columns)
importances_sorted = importances.sort_values(ascending=False)[:20]

# Plot top 20 features
plt.figure(figsize=(10, 6))
importances_sorted.plot(kind='barh')
plt.title("Top 20 Feature Importances (Random Forest)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">Linear Regression</font></b></h2>"""

# Training Linear Regression Model
#This code trains Linear Regression model to predict runs, and prints out how well the model performed using MAE and R2 metrics
lr_odi_bowl = LinearRegression()
lr_odi_bowl.fit(X_train, y_train)

# Predict on test data
y_pred_lr = lr_odi_bowl.predict(X_test)
y_pred_lr_rounded = np.round(y_pred_lr).astype(int)

# Evaluation
mae_lr = mean_absolute_error(y_test, y_pred_lr_rounded)
r2_lr = r2_score(y_test, y_pred_lr_rounded)

print("🎯 Linear Regression (Wickets Prediction)")
print(f"MAE: {mae_lr:.3f}")
print(f"R²: {r2_lr:.3f}")

# Create a DataFrame to compare actual and predicted values
results_lr_df = pd.DataFrame({
    'Actual Wickets': y_test.values,
    'Predicted Wickets': y_pred_lr_rounded
})

# Show top 20 rows
print(results_lr_df.head(20))

# Feature importances (coefficients)
coefs = pd.Series(lr_odi_bowl.coef_, index=X.columns)
coefs_sorted = coefs.sort_values(ascending=False)[:20]

# Plot top 20 coefficients
plt.figure(figsize=(10, 6))
coefs_sorted.plot(kind='barh')
plt.title("Top 20 Coefficients (Linear Regression)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">XGBoost</font></b></h2>"""

# Training XGBoost Model
#This code trains a XGBoost model to predict runs, and prints out how well the model performed using MAE and R2 metrics
xgb_odi_bowl = XGBRegressor(n_estimators=100, learning_rate=0.1, max_depth=5, random_state=42)
xgb_odi_bowl.fit(X_train, y_train)

# Predict on test data
y_pred_xgb = xgb_odi_bowl.predict(X_test)
y_pred_xgb_rounded = np.round(y_pred_xgb).astype(int)

# Evaluation
mae_xgb = mean_absolute_error(y_test, y_pred_xgb_rounded)
r2_xgb = r2_score(y_test, y_pred_xgb_rounded)

print("🎯 XGBoost Regressor (Wickets Prediction)")
print(f"MAE: {mae_xgb:.3f}")
print(f"R²: {r2_xgb:.3f}")

# Create a DataFrame to compare actual and predicted values
results_xgb_df = pd.DataFrame({
    'Actual Wickets': y_test.values,
    'Predicted Wickets': y_pred_xgb_rounded
})

# Show top 20 rows
print(results_xgb_df.head(20))

# Feature importances
importances_xgb = pd.Series(xgb_odi_bowl.feature_importances_, index=X.columns)
importances_xgb_sorted = importances_xgb.sort_values(ascending=False)[:20]

# Plot top 20 features
plt.figure(figsize=(10, 6))
importances_xgb_sorted.plot(kind='barh')
plt.title("Top 20 Feature Importances (XGBoost)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">LightGBM</font></b></h2>"""

# Training LightGBM Model
#This code trains a LightGBM model to predict runs, and prints out how well the model performed using MAE and R2 metrics
import lightgbm as lgb

X.columns = X.columns.str.replace(' ', '_')

lgb_odi_bowl = lgb.LGBMRegressor(
    n_estimators=700,
    learning_rate=0.04,
    max_depth=7,
    num_leaves=35,
    subsample=0.85,
    colsample_bytree=0.85,
    random_state=42,
    verbose=-1,
    n_jobs=-1
)
lgb_odi_bowl.fit(X_train, y_train)

# Predict on test data
y_pred_lgb = lgb_odi_bowl.predict(X_test)
y_pred_lgb_rounded = np.round(y_pred_lgb).astype(int)

# Evaluation
mae_lgb = mean_absolute_error(y_test, y_pred_lgb_rounded)
r2_lgb = r2_score(y_test, y_pred_lgb_rounded)

print("🎯 LightGBM Regressor (Wickets Prediction)")
print(f"MAE: {mae_lgb:.3f}")
print(f"R²: {r2_lgb:.3f}")

# Create a DataFrame to compare actual and predicted values
results_lgb_df = pd.DataFrame({
    'Actual Wickets': y_test.values,
    'Predicted Wickets': y_pred_lgb_rounded
})

# Show top 20 rows
print(results_lgb_df.head(20))

# Feature importances
importances_lgb = pd.Series(lgb_odi_bowl.feature_importances_, index=X.columns)
importances_lgb_sorted = importances_lgb.sort_values(ascending=False)[:20]

# Plot top 20 features
plt.figure(figsize=(10, 6))
importances_lgb_sorted.plot(kind='barh')
plt.title("Top 20 Feature Importances (LightGBM)")
plt.gca().invert_yaxis()
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">Standardization</font></b></h2>"""

# Fix column names before scaling
X.columns = X.columns.str.replace(' ', '_')

# Standardizing features and preserving column names
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns)

# Train-test split
X_train_std, X_test_std, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.2, random_state=42
)

# Training and evaluating models

# Random Forest
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train_std, y_train)
y_pred_rf = np.round(rf.predict(X_test_std)).astype(int)
mae_rf = mean_absolute_error(y_test, y_pred_rf)
r2_rf = r2_score(y_test, y_pred_rf)
print(f"Random Forest (Rounded): MAE: {mae_rf:.3f} R2: {r2_rf:.3f}")

# Linear Regression
lr = LinearRegression()
lr.fit(X_train_std, y_train)
y_pred_lr = np.round(lr.predict(X_test_std)).astype(int)
mae_lr = mean_absolute_error(y_test, y_pred_lr)
r2_lr = r2_score(y_test, y_pred_lr)
print(f"Linear Regression (Rounded): MAE: {mae_lr:.3f} R2: {r2_lr:.3f}")

# XGBoost
xgb_reg = XGBRegressor(random_state=42, verbosity=0)
xgb_reg.fit(X_train_std, y_train)
y_pred_xgb = np.round(xgb_reg.predict(X_test_std)).astype(int)
mae_xgb = mean_absolute_error(y_test, y_pred_xgb)
r2_xgb = r2_score(y_test, y_pred_xgb)
print(f"XGBoost (Rounded): MAE: {mae_xgb:.3f} R2: {r2_xgb:.3f}")

# LightGBM
lgb_reg = LGBMRegressor(random_state=42)
lgb_reg.fit(X_train_std, y_train)
y_pred_lgb = np.round(lgb_reg.predict(X_test_std)).astype(int)
mae_lgb = mean_absolute_error(y_test, y_pred_lgb)
r2_lgb = r2_score(y_test, y_pred_lgb)
print(f"LightGBM (Rounded): MAE: {mae_lgb:.3f} R2: {r2_lgb:.3f}")

"""<h2><b><font color="gold">Normalization</font></b></h2>"""

# # Normalizing and preserving feature names
# scaler_norm = MinMaxScaler()
# X_norm = pd.DataFrame(scaler_norm.fit_transform(X), columns=X.columns)

# # Train-test split
# X_train_norm, X_test_norm, y_train_norm, y_test_norm = train_test_split(X_norm, y, test_size=0.2, random_state=42)

# Training and evaluating models

#  Random Forest
rf = RandomForestRegressor(random_state=42)
rf.fit(X_train_norm, y_train_norm)
y_pred_rf = np.round(rf.predict(X_test_norm)).astype(int)
mae_rf = mean_absolute_error(y_test_norm, y_pred_rf)
r2_rf = r2_score(y_test_norm, y_pred_rf)
print(f"Random Forest (Rounded): MAE: {mae_rf:.3f} R2: {r2_rf:.3f}")

#  Linear Regression
lr = LinearRegression()
lr.fit(X_train_norm, y_train_norm)
y_pred_lr = np.round(lr.predict(X_test_norm)).astype(int)
mae_lr = mean_absolute_error(y_test_norm, y_pred_lr)
r2_lr = r2_score(y_test_norm, y_pred_lr)
print(f"Linear Regression (Rounded): MAE: {mae_lr:.3f} R2: {r2_lr:.3f}")

#  XGBoost
xgb_reg = XGBRegressor(random_state=42, verbosity=0)
xgb_reg.fit(X_train_norm, y_train_norm)
y_pred_xgb = np.round(xgb_reg.predict(X_test_norm)).astype(int)
mae_xgb = mean_absolute_error(y_test_norm, y_pred_xgb)
r2_xgb = r2_score(y_test_norm, y_pred_xgb)
print(f"XGBoost (Rounded): MAE: {mae_xgb:.3f} R2: {r2_xgb:.3f}")

#  LightGBM
lgb_reg = LGBMRegressor(random_state=42)
lgb_reg.fit(X_train_norm, y_train_norm)
y_pred_lgb = np.round(lgb_reg.predict(X_test_norm)).astype(int)
mae_lgb = mean_absolute_error(y_test_norm, y_pred_lgb)
r2_lgb = r2_score(y_test_norm, y_pred_lgb)
print(f"LightGBM (Rounded): MAE: {mae_lgb:.3f} R2: {r2_lgb:.3f}")

"""<h2><b><font color="gold">LightGBM Hyperparameter Tuning</font></b></h2>

"""

# Defining the parameter grid
param_dist = {
    'num_leaves': [15, 31, 63, 127],
    'max_depth': [-1, 5, 10, 15],
    'learning_rate': [0.01, 0.05, 0.1, 0.2],
    'n_estimators': [100, 200, 300, 500],
    'min_child_samples': [5, 10, 20, 30],
    'subsample': [0.6, 0.8, 1.0],
    'colsample_bytree': [0.6, 0.8, 1.0]
}

X.columns = X.columns.str.replace(' ', '_')

# Initialize model
lgbm = LGBMRegressor(random_state=42, verbose=-1)

# RandomizedSearchCV
random_search = RandomizedSearchCV(
    estimator=lgbm,
    param_distributions=param_dist,
    n_iter=30,  # reduce if very slow
    scoring='neg_mean_absolute_error',
    cv=3,
    random_state=42,
    n_jobs=-1
)

# Fit the random search
random_search.fit(X_train, y_train)

# Predicting and evaluating
best_lgbm = random_search.best_estimator_
y_pred = np.round(best_lgbm.predict(X_test)).astype(int)

mae = mean_absolute_error(y_test, y_pred)
r2 = r2_score(y_test, y_pred)

print("Best Parameters:", random_search.best_params_)
print(f"Tuned LightGBM (Rounded): MAE: {mae:.3f}, R2: {r2:.3f}")

results = pd.DataFrame({
    'Actual': y_test.values.astype(int),
    'Predicted (rounded)': y_pred.astype(int)
})
print(results.head(20))

# Use your tuned model from RandomizedSearchCV
importances_lgb = pd.Series(best_lgbm.feature_importances_, index=X.columns)
importances_lgb_sorted = importances_lgb.sort_values(ascending=False).head(20)

plt.figure(figsize=(10, 6))
importances_lgb_sorted.plot(kind='barh')
plt.title("Top 20 Feature Importances (Tuned LightGBM)")
plt.gca().invert_yaxis()
plt.xlabel("Importance")
plt.tight_layout()
plt.show()

"""<h2><b><font color="gold">SHAP explanations for tuned LightGBM </font></b></h2>"""

import shap

# Use a small sample of X_test for speed (uses all if smaller than 1000)
X_explain = X_test.sample(n=min(1000, len(X_test)), random_state=42)

# Build explainer and compute SHAP values
explainer = shap.TreeExplainer(best_lgbm)
shap_values = explainer.shap_values(X_explain)

"""***SHAP Beeswarm Plot***"""

# SHAP beeswarm showing impact of each feature on individual predictions
plt.figure(figsize=(12, 8))
shap.summary_plot(
    shap_values,
    X_explain,
    max_display=10,
    show=False
)
plt.title("SHAP value (impact on model output)")
plt.tight_layout()
plt.show()

"""***SHAP Bar Plot***

"""

# SHAP bar chart showing average absolute impact of each feature
plt.figure(figsize=(12, 8))
shap.summary_plot(
    shap_values,
    X_explain,
    plot_type="bar",
    max_display=10,
    show=False
)
plt.title("mean(|SHAP value|) – average impact on model output")
plt.xlabel("mean(|SHAP value|) (average impact on model output)")
plt.tight_layout()
plt.show()

"""***SHAP Single-Feature Dependence Plot***"""

# SHAP dependence plot showing how one feature’s values affect predictions

# Pick the top feature by mean absolute SHAP value
mean_abs = np.abs(shap_values).mean(axis=0)
top_idx = np.argsort(mean_abs)[-1]
top_feat = X_explain.columns[top_idx]   # e.g., "vs_venue_wickets"

plt.figure(figsize=(10, 6))
shap.dependence_plot(
    top_feat,          # feature to visualize
    shap_values,       # SHAP values from explainer
    X_explain,         # data sample used for explanations
    show=False
)
plt.title(f"SHAP Dependence Plot – {top_feat}")
plt.tight_layout()
plt.show()